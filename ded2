import pandas as pd
import numpy as np
import umap
import hdbscan
from tqdm import tqdm
from sentence_transformers import SentenceTransformer

# Load Data
df = pd.read_csv("incident_gaf1_100k.csv", encoding="latin1")
df["short_description"] = df["short_description"].fillna("")
texts = df["short_description"].tolist()

# Load Embedding Model
model = SentenceTransformer("all-MiniLM-L6-v2")

# Generate Embeddings (Batch Processing for Stability)
embeddings = []
batch_size = 128
for i in tqdm(range(0, len(texts), batch_size), desc="Encoding Texts"):
    batch = texts[i:i + batch_size]
    try:
        batch_embeddings = model.encode(batch, convert_to_numpy=True)
        embeddings.append(batch_embeddings)
    except Exception as e:
        print(f"Error encoding batch {i}: {e}")

# Stack All Embeddings
embeddings = np.vstack(embeddings) if embeddings else np.array([])

if embeddings.shape[0] == 0:
    print("Embedding generation failed. Exiting clustering.")
else:
    # Reduce Dimensionality with UMAP
    reducer = umap.UMAP(n_neighbors=10, n_components=2, min_dist=0.0, metric="cosine", random_state=42, low_memory=True)
    reduced_embeddings = reducer.fit_transform(embeddings)

    # Run HDBSCAN Clustering
    clusterer = hdbscan.HDBSCAN(min_cluster_size=10, min_samples=1, metric="euclidean", cluster_selection_method="eom", prediction_data=True, core_dist_n_jobs=2, probability=True)
    labels = clusterer.fit_predict(reduced_embeddings)
    cluster_probs = clusterer.probabilities_

    # Store Results
    df["Cluster"] = labels
    df["Cluster Confidence"] = cluster_probs
