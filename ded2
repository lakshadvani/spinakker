import pandas as pd
import numpy as np
import umap
import hdbscan
import faiss
from tqdm import tqdm
from sentence_transformers import SentenceTransformer

# Load Data
df = pd.read_csv("incident_gaf1_100k.csv", encoding="latin1")
df["short_description"] = df["short_description"].fillna("")
texts = df["short_description"].tolist()

# Load Embedding Model
model = SentenceTransformer("all-MiniLM-L6-v2")

# Generate Embeddings (Batch Processing for Stability)
embeddings = []
batch_size = 128
for i in tqdm(range(0, len(texts), batch_size), desc="Encoding Texts"):
    batch = texts[i:i + batch_size]
    try:
        batch_embeddings = model.encode(batch, convert_to_numpy=True)
        embeddings.append(batch_embeddings)
    except Exception as e:
        print(f"Error encoding batch {i}: {e}")

# Stack All Embeddings
embeddings = np.vstack(embeddings) if embeddings else np.array([])

if embeddings.shape[0] == 0:
    print("Embedding generation failed. Exiting clustering.")
else:
    # Use FAISS for Faster Nearest Neighbor Search in UMAP
    index = faiss.IndexFlatL2(embeddings.shape[1])  # Create FAISS L2 index
    index.add(embeddings)  # Add embeddings to FAISS index
    _, neighbors = index.search(embeddings, 10)  # Find top 10 nearest neighbors

    # Reduce Dimensionality with UMAP
    reducer = umap.UMAP(
        n_neighbors=10, n_components=2, min_dist=0.0, metric="cosine", 
        random_state=42, low_memory=True
    )
    reduced_embeddings = reducer.fit_transform(embeddings, neighbors=neighbors)

    # Run HDBSCAN Clustering
    clusterer = hdbscan.HDBSCAN(
        min_cluster_size=10, min_samples=1, metric="euclidean", 
        cluster_selection_method="eom", core_dist_n_jobs=2
    )
    labels = clusterer.fit_predict(reduced_embeddings)

    # Get Cluster Probabilities (Soft Clustering)
    cluster_probs = clusterer.membership_vector_ if hasattr(clusterer, "membership_vector_") else np.zeros(len(labels))

    # Store Results
    df["Cluster"] = labels
    df["Cluster Confidence"] = [max(p) if len(p) > 0 else 0 for p in cluster_probs]
